import torch
import logging
import gc
import math

try:
    import deepspeed
    from deepspeed import DeepSpeedEngine
except:
    deepspeed = None
    DeepSpeedEngine = None

import accelerate
from accelerate import Accelerator

from transformers import AdamW

# from torch.optim import AdamW

from federatedscope.register import register_trainer
from federatedscope.core.trainers import GeneralTorchTrainer
from federatedscope.core.trainers.context import CtxVar, lifecycle
from federatedscope.core.trainers.enums import MODE, LIFECYCLE
from federatedscope.core.monitors.monitor import Monitor
from federatedscope.core.data.wrap_dataset import WrapDataset
from federatedscope.core.auxiliaries.dataloader_builder import get_dataloader
from federatedscope.core.auxiliaries.ReIterator import ReIterator
from federatedscope.core.auxiliaries.optimizer_builder import get_optimizer
from federatedscope.core.auxiliaries.scheduler_builder import get_scheduler
from federatedscope.llm.model.adapter_builder import AdapterModel
from federatedscope.llm.dataloader.dataloader import get_tokenizer



from federatedscope.core.auxiliaries.decorators import use_diff




logger = logging.getLogger(__name__)

import sys

sys.setrecursionlimit(100000)





class LLMTrainer(GeneralTorchTrainer): #**Large Language Model (LLM)**ì„ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í™•ì¥ëœ ë²„ì „.

#ì¦‰, ì¼ë°˜ì ì¸ Trainerë¡œëŠ” ë„ˆë¬´ ëŠë¦¬ê±°ë‚˜ ë©”ëª¨ë¦¬ë¥¼ ë„ˆë¬´ ë§ì´ ì¡ì•„ë¨¹ëŠ” LLMì„ í•™ìŠµí•˜ë ¤ë©´,ë‹¤ìŒ ë‘ ê°€ì§€ê°€ í•„ìš”í•¨.
#### 1. íš¨ìœ¨ì ì¸ ë©”ëª¨ë¦¬ ê´€ë¦¬ì™€ GPU ë¶„ì‚° í•™ìŠµ â†’ DeepSpeed -> ì‹¤ì œë¡œ ì ìš© ì•ˆí•¨.
#### 2. Mixed precision (ì˜ˆ: bf16)ê³¼ gradient accumulation â†’ Accelerate-> ì´ê²Œ ì‹¤ì œë¡œ ì ìš©ë¨.


    def __init__(self,
                 model,
                 data,
                 device,
                 config,
                 only_for_eval=False,
                 monitor=None):
        num_train_batch = len(data['train'])#train dataloaderì˜ length. micro batch size ê¸°ì¤€ ì •í•´ì§„ ê²ƒ.


        """

        ìš°ë¦¬ê°€ ìƒê°í•˜ëŠ” ê²ƒì€ effective_batch

        effective batch size = batch_size Ã— grad_accum_step (1-gpu)

        effectiveÂ batchÂ size = per_device_batch_size Ã— grad_accum_step Ã— world_sizeÂ (í”„ë¡œì„¸ìŠ¤Â ìˆ˜) (ë‹¤ì¤‘ gpu, DDP)



        ì´ë¥¼ ê³ ë ¤í•˜ì—¬ grad_accum_step, world_size ë“±ì„ ê³ ë ¤í•˜ë©´ ëœë‹¤.


        LLM í•™ìŠµìš©: llm.grad_accum_step â†’ LLM forward/backward ë°˜ë³µ íšŸìˆ˜

        ì¼ë°˜ í•™ìŠµìš©: grad.grad_accum_count â†’ non-LLM forward/backward ë°˜ë³µ íšŸìˆ˜

        
        """



        #Gradient Accumulation Step ê³„ì‚°â†’ í•œ ë²ˆì˜ optimizer.step()ì„ ì—¬ëŸ¬ mini-batchì— ê±¸ì³ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤. 
        self.grad_accum_step = min(
            num_train_batch,
            max(config.llm.grad_accum_step, config.grad.grad_accum_count)) #config.llm.grad_accum_step
        
        
        #Accelerator ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ Accelerator ì´ˆê¸°í™”->ì´ê±´ ğŸ¤– HuggingFace accelerate ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, bf16 í•™ìŠµ ë° ìë™ Device ë°°ë¶„, gradient accumulate, DDP ë“±ì„ ì‰½ê²Œ í•´ì£¼ëŠ” wrapperì…ë‹ˆë‹¤.

        # if config.llm.accelerator.use: #TRUE. 

        #     """
        #     Accelerator.state ë‚´ë¶€ ë™ê¸°í™” êµ¬ì¡°

        #         accelerator.state.process_index  # í˜„ì¬ í”„ë¡œì„¸ìŠ¤ ë²ˆí˜¸
        #         accelerator.state.num_processes  # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ìˆ˜
        #         accelerator.state.device         # = accelerator.device
        #     """

        #     self.accelerator = Accelerator(
        #         gradient_accumulation_steps=self.grad_accum_step,
        #         mixed_precision='bf16')
            
        #     device = self.accelerator.device #self.accelerator.deviceëŠ” í•´ë‹¹ í”„ë¡œì„¸ìŠ¤ê°€ ë§¡ì€ GPU device (torch.device) ê°ì²´



        super().__init__(model, data, device, config, only_for_eval, monitor)
        model_name, _ = config.model.type.split('@')

        #tokenizer ì¤€ë¹„
        self.tokenizer, _ = get_tokenizer(model_name, config.data.root,
                                          config.llm.tok_len)
        
        self.eval_metrics = config.eval.metrics #[loss, acc]

    def register_default_hooks_train(self):
        super().register_default_hooks_train()

        #ì¶”ê°€ì ìœ¼ë¡œ memory ì ˆì•½ìš© hook ë“±ë¡
        self.register_hook_in_train(self._hook_on_fit_end_free_space,
                                    "on_fit_end")

    def register_default_hooks_ft(self):
        super().register_default_hooks_ft()
        #ì¶”ê°€ì ìœ¼ë¡œ memory ì ˆì•½ìš© hook ë“±ë¡:
        self.register_hook_in_ft(self._hook_on_fit_end_free_space,
                                 "on_fit_end")

    def register_default_hooks_eval(self):
        super().register_default_hooks_eval()
        #ì¶”ê°€ì ìœ¼ë¡œ memory ì ˆì•½ìš© hook ë“±ë¡:
        self.register_hook_in_eval(self._hook_on_fit_end_free_space,
                                   "on_fit_end")

    @lifecycle(LIFECYCLE.BATCH)
    #ì—…ë°ì´íŠ¸ 1íšŒë¥¼ ì–´ë–»ê²Œ ë§Œë“œëŠ”ì§€ë¥¼ ê²°ì •.
    def _run_batch(self, hooks_set, run_step=-1): #í•œ epoch ë‚´ì—ì„œ batch 1ê°œ ë„ëŠ” ê±¸ ì—¬ëŸ¬ë²ˆ ë°˜ë³µ. run_epochì—ì„œëŠ” run_step=-1 ì ìš©. ë‹¤ë¥¸ ê³³ì—ì„œëŠ” run_step=1 ì ìš©.
        # 1) grad_accum_step
        if self.ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
            grad_accum_step = self.grad_accum_step
        else:
            grad_accum_step = 1  #EVAL ëª¨ë“œë©´ ëˆ„ì  ì—†ì´ í•œ ë°°ì¹˜ì”© ì²˜ë¦¬

        split = self.ctx.cur_split
        loader = self.ctx.get(f"{split}_loader")
        if loader is None:
            return



        # DDPì¼ ë•Œ ë§¤ epochë§ˆë‹¤ ëª¨ë“  ë­í¬ê°€ ë™ì¼í•œ ì…”í”Œ ì‹œë“œ ì²´ê³„ë¥¼ ê³µìœ í•˜ê¸° ìœ„í•´ ë§¤ ì—í­ë§ˆë‹¤ set_epoch. 
        # ê° í”„ë¡œì„¸ìŠ¤ê°€ ê°€ì§„ DataLoader í•˜ë‚˜ê°€ DistributedSampler(rank, num_replicas) ë•Œë¬¸ì— â€˜ìê¸° ëª«â€™ë§Œ ì½ê²Œ í•¨.

        """
        ê° ë­í¬ëŠ” ìê¸° shardì—ì„œ ë‹¤ìŒ ë§ˆì´í¬ë¡œë°°ì¹˜ë¥¼ ìˆœì„œëŒ€ë¡œ ì†Œëª¨.

        effective batch: í•œ â€œì—…ë°ì´íŠ¸ 1íšŒâ€ ë™ì•ˆ

        ë­í¬ë³„ë¡œ per_process_batch_size Ã— grad_accum_step ìƒ˜í”Œ ì†Œë¹„

        ì „ ë­í¬ í•©ì¹˜ë©´ per_process_batch_size Ã— grad_accum_step Ã— world_size (= ê¸€ë¡œë²Œ ìœ íš¨ë°°ì¹˜)

        """

        if split == "train":
            sampler = getattr(loader, "sampler", None)
            try:
                from torch.utils.data.distributed import DistributedSampler
                if isinstance(sampler, DistributedSampler): #True
                    epoch_seed = int(getattr(self.ctx, "cur_epoch_i", 0))
                    sampler.set_epoch(epoch_seed)
            except Exception:
                pass


        iter_name = f"{split}_loader_iter"

        if self.ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
            if run_step == -1: #train ë–„ ì¼ë°˜ì ìœ¼ë¡œ ì´ê²ƒì— ê±¸ë¦¼.
                num_batches = getattr(self.ctx, f"num_{split}_batch") ##ì¼ë°˜ì ì¸ epochë‹¹ batch ê°œìˆ˜. ë‹¤ë§Œ batch_or_epoch == "batch"ì´ë©´ iteration ìˆ˜ì™€ ë¹„êµí–ˆì„ ë•Œ min ê°’ìœ¼ë¡œ ì„¤ì •ë¨.

                if hasattr(self, 'accelerator') and self.accelerator is not None:
                    # (microbatch size*grad_accum_step) ì‚¬ì´ì¦ˆë¥¼ num_batchesë§Œí¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•¨

                    #ë£¨í”„ ë³¸ë¬¸: with self.accelerator.accumulate: ì•ˆì—ì„œ ë§ˆì´í¬ë¡œë°°ì¹˜ 1ê°œ ì²˜ë¦¬
                    #ê²°ê³¼: ë§ˆì´í¬ë¡œë°°ì¹˜ ì´ ì†Œë¹„ëŸ‰ì´ NÃ—gê°€ ë˜ì–´, ë°ì´í„°ì…‹ì„ gë°° ë” ë
                    run_step = num_batches * max(1, grad_accum_step)

                else: #ì•ˆìª½ì—ì„œ for k in range(grad_accum_step)ë¡œ ë§ˆì´í¬ë¡œë°°ì¹˜ grad_accum_stepê°œ ì²˜ë¦¬ â†’ ì—…ë°ì´íŠ¸ 1íšŒ
                    run_step = math.ceil(num_batches / max(1, grad_accum_step))


             # ì´í„°ë ˆì´í„°: í•„ìš”ì‹œ ì¬ì‹œì‘(ë°ì´í„°ê°€ ë” ì ì€ ê²½ìš°ë¥¼ ëŒ€ë¹„)
            if not hasattr(self.ctx, iter_name):
                setattr(self.ctx, iter_name, iter(loader))
            data_loader_iter = getattr(self.ctx, iter_name)

        else:
            # âœ… TEST, VAL: ìƒ¤ë”©ëœ ë¡œë” ê¸¸ì´ë§Œí¼ë§Œ 1íšŒ(grad_accum_step = 1)
            if run_step == -1:
                run_step = len(loader) #microbatch size ê¸°ì¤€ ê¸¸ì´.
            # ì´í„°ë ˆì´í„°: ë§¤ í‰ê°€ ë£¨í‹´ë§ˆë‹¤ ìƒˆë¡œ ì‹œì‘, StopIteration â†’ ì¢…ë£Œ
            data_loader_iter = iter(loader)
            setattr(self.ctx, iter_name, data_loader_iter)

        exhausted = False
        for update_i in range(run_step):
            self.ctx.cur_batch_i = CtxVar(update_i, LIFECYCLE.BATCH)

            if hasattr(self, 'accelerator'): #accelerator ëª¨ë“œì—ì„œ ì‹¤í–‰. 
                # âœ… grad_accum_step ë£¨í”„ ì œê±°: accumulate ë¸”ë¡ë§Œ ì‚¬ìš©
                try:
                    self.ctx.data_batch = next(data_loader_iter)
                except StopIteration:
                    if self.ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
                        # TRAIN: ìŠ¤í…ì´ ë‚¨ì•„ ìˆìœ¼ë©´ ë°ì´í„° ì¬ì‹œì‘
                        data_loader_iter = iter(loader)
                        setattr(self.ctx, iter_name, data_loader_iter)
                        try:
                            self.ctx.data_batch = next(data_loader_iter)
                        except StopIteration:
                            exhausted = True
                            break
                    else:
                        # EVAL: ì¬ì‹œì‘í•˜ì§€ ì•Šê³  ì¢…ë£Œ
                        exhausted = True
                        break

                #AccelerateëŠ” ë‚´ë¶€ ì¹´ìš´í„°ë¡œ self.grad_accum_step-1ë²ˆì€ no_sync(í†µì‹ /step ì—†ìŒ), self.grad_accum_stepë²ˆì§¸ì—ë§Œ all-reduce + step.
                #ë”°ë¼ì„œ ì—…ë°ì´íŠ¸ 1íšŒ = ì´ ë¸”ë¡ì´ self.grad_accum_stepë²ˆ ì‹¤í–‰ëœ ì‹œì .
                with self.accelerator.accumulate(self.ctx.model): #ë§ˆì´í¬ë¡œë°°ì¹˜ 1ê°œë¥¼ ì²˜ë¦¬í•˜ëŠ” ë‹¨ìœ„ ë¸”ë¡.
                    for hook in hooks_set["on_batch_start"]:
                        hook(self.ctx)
                    for hook in hooks_set["on_batch_forward"]:
                        hook(self.ctx)
                    for hook in hooks_set["on_batch_backward"]:
                        hook(self.ctx)
                    for hook in hooks_set["on_batch_end"]:
                        hook(self.ctx)


            else:
                for k in range(grad_accum_step):
                    self.ctx.cur_batch_i = CtxVar(update_i * grad_accum_step + k,
                                                LIFECYCLE.BATCH)
                    try:
                        self.ctx.data_batch = next(data_loader_iter)
                    except StopIteration:
                        if self.ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
                            data_loader_iter = iter(loader)
                            setattr(self.ctx, iter_name, data_loader_iter)
                            try:
                                self.ctx.data_batch = next(data_loader_iter)
                            except StopIteration:
                                exhausted = True
                                break
                        else:
                            exhausted = True
                            break

                    for hook in hooks_set["on_batch_start"]:
                        hook(self.ctx)
                    for hook in hooks_set["on_batch_forward"]:
                        hook(self.ctx)
                    for hook in hooks_set["on_batch_backward"]:
                        hook(self.ctx)
                    for hook in hooks_set["on_batch_end"]:
                        hook(self.ctx)

            if exhausted:
                break

            # Break in the final epoch
            if self.ctx.cur_mode in [
                    MODE.TRAIN, MODE.FINETUNE
            ] and self.ctx.cur_epoch_i == self.ctx.num_train_epoch - 1:# í•™ìŠµ/íŒŒì¸íŠœë‹ ëª¨ë“œ í™•ì¸ ë° ë§ˆì§€ë§‰ ì—í­ì¸ì§€ í™•ì¸
                if update_i >= self.ctx.num_train_batch_last_epoch - 1: #ë§ˆì§€ë§‰ ì—í­ì˜ ì‹¤ì œ ìŠ¤í…(ì—…ë°ì´íŠ¸) ìˆ˜ ì´ˆê³¼ ì—¬ë¶€ íŒì •
                    break #ì¡°ê¸° ì¢…ë£Œ(break)    







    # @lifecycle(LIFECYCLE.BATCH) #íŠ¹ë³„í•œ ì¼ ì—†ìœ¼ë©´ .run_step=1ë¡œ ì‹¤í–‰ë˜ëŠ” ìƒí™©.
    # #ë°°ì¹˜ ë£¨í”„ ì˜¤ë²„ë¼ì´ë“œ, í•œ ì—í­(epoch) ë™ì•ˆì˜ ë¡œì»¬ í•™ìŠµ â€œë°°ì¹˜ ì²˜ë¦¬â€ ì „ì²´ë¥¼ ë‹´ë‹¹í•˜ëŠ” ë©”ì„œë“œ
    # def _run_batch(self, hooks_set, run_step=-1):  #Accelerator.accumulate ê¸°ë°˜ gradient accumulation êµ¬í˜„, ìƒˆë¡œ ì¶”ê°€ëœ ê±°ì„. run_step: ì™¸ë¶€ ë£¨í”„ íšŸìˆ˜; ê¸°ë³¸ê°’ -1 ì´ë©´ ì•„ë˜ì—ì„œ ìƒˆë¡œ ê³„ì‚°

    #     """
    #     self._cfg.train.batch_or_epochì— ë”°ë¼ ë£¨í”„ë¥¼ ë‹¤ë¥´ê²Œ ì ìš©.

    #     run_step = getattr(self.ctx, f"num_{self.ctx.cur_split}_batch")ì€ micro batch ê¸°ì¤€ í•œ epochë‹¹ iteration ê°¯ìˆ˜ì„.


    #     1. epochì¼ ë–„:

    #         run_step ìˆ˜ë¥¼ micro batchê°€ ì•„ë‹Œ effective batch ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •. -> grad_accum_stepë¡œ ë‚˜ëˆ ì¤€ë‹¤.

    #         grad_accum_step * run_step =getattr(self.ctx, f"num_{self.ctx.cur_split}_batch") ë˜ê²Œ í•¨.


    #     2. batchì¼ ë–„:
    #         run_step ìˆ˜ë¥¼ micro batchê°€ ê¸°ì¤€ í•œ epochë‹¹ iteration ê°¯ìˆ˜ë¡œ ìœ ì§€

    #         ì´ë¡œ ì¸í•´ í•œ epochì„ effect batch ì‚¬ì´ì¦ˆì˜ batchë¥¼ micro batchê°€ ê¸°ì¤€ í•œ epochë‹¹ iteration ê°¯ìˆ˜ë§Œí¼ ëŒë¦¬ë ¤ í•¨.
        
    #     """

 

    #     #grad_accum_step ê³„ì‚°

    #     if self.ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]: #train, ft ì¸ ìƒí™© í•œí•´ì„œë§Œ
    #         grad_accum_step = self.grad_accum_step #onfigì— ì„¤ì •ëœ self.grad_accum_stepë§Œí¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê·¸ë¼ë””ì–¸íŠ¸ë¥¼ ëˆ„ì (accumulate)
    #     else: #eval
    #         grad_accum_step = 1 #EVAL ëª¨ë“œë©´ ëˆ„ì  ì—†ì´ í•œ ë°°ì¹˜ì”© ì²˜ë¦¬


        
    #     if run_step == -1: #run_epochì—ì„œ -1ë¡œ ë°˜ì˜.
    #         run_step = getattr(self.ctx, f"num_{self.ctx.cur_split}_batch")#ì›ë˜ í•œ ì—í­ë‹¹ ë°°ì¹˜ ìˆ˜ ê³„ì‚°, e.g.) ë°ì´í„°ì…‹ì— 100ê°œì˜  micro ë¯¸ë‹ˆ ë°°ì¹˜(batch)ê°€ ìˆìœ¼ë©´ run_step = 100 ì´ ë©ë‹ˆë‹¤. effective batch size ê¸°ì¤€ì´ ì•„ë‹˜.


    #         if self._cfg.train.batch_or_epoch == 'epoch': # í•œ ì—í­ ë‹¹ ì—…ë°ì´íŠ¸ íšŸìˆ˜ = #effective batch size ê¸°ì¤€ìœ¼ë¡œ run_stepì´ ë°”ë€œ.
    #             run_step = math.ceil(run_step / grad_accum_step) #effective batch size ê¸°ì¤€ìœ¼ë¡œ run_stepì´ ë°”ë€œ.
    #             #grad_accum_stepì´ 4ë¼ë©´, 4ê°œ ë¯¸ë‹ˆë°°ì¹˜ë¥¼ ëª¨ì•„ì„œ í•œ ë²ˆì˜ backward+update ë¥¼ í•˜ê² ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.
    #             #ë”°ë¼ì„œ ì—…ë°ì´íŠ¸ íšŸìˆ˜ = 100 Ã· 4 = 25 (ë‚˜ë¨¸ì§€ ì²˜ë¦¬ ìœ„í•´ ceil) â†’ run_step = 25
    #             #ë§Œì•½ ì´ ë‚˜ëˆ—ì…ˆì´ ì—†ìœ¼ë©´, ì™¸ë¶€ ë£¨í”„ê°€ 100ë²ˆ ëŒì•„ê°€ë©´ì„œ ë‚´ë¶€ì—ì„œ ë˜ 4ë²ˆì”© mini-batchë¥¼ ì²˜ë¦¬í•´ ë²„ë ¤, ì‹¤ì œë¡œ 400ê°œì˜ ë°°ì¹˜ë¥¼ ì½ê²Œ ë¼ ë²„ë¦½ë‹ˆë‹¤.

    #     # --- ë°ì´í„°ë¡œë” ì´í„°ë ˆì´í„° ì¤€ë¹„ ---
    #     iter_name = f"{self.ctx.cur_split}_loader_iter"
    #     if not hasattr(self.ctx, iter_name):
    #         data_loader = self.ctx.get(f"{self.ctx.cur_split}_loader")
    #         if data_loader is not None:
    #             setattr(self.ctx, iter_name, iter(data_loader))
    #     if not hasattr(self.ctx, iter_name):
    #         return

    #     data_loader_iter = getattr(self.ctx, iter_name)




    #     for batch_i in range(run_step): #self._cfg.train.batch_or_epoch == 'epoch'ì¼ ë–„  batch_iëŠ” â€œì—…ë°ì´íŠ¸ ìŠ¤í… ì¸ë±ìŠ¤â€ (0â€¦24) ì…ë‹ˆë‹¤. effective batchì˜ index. 
    #         #batch_iê°€ effective batchë¥¼ ì˜ë¯¸í•˜ëŠ” ìƒí™©.
    #         self.ctx.cur_batch_i = CtxVar(batch_i, LIFECYCLE.BATCH) #ctx.cur_batch_iì— ì €ì¥í•˜ë©´, í›…ì´ë‚˜ ë¡œê¹… ë¡œì§ì´ ì´ ìŠ¤í… ë²ˆí˜¸ë¥¼ ì°¸ì¡° ê°€ëŠ¥. 
            
    #         if hasattr(self, 'accelerator'): #accelerator ëª¨ë“œì—ì„œ ì‹¤í–‰. with self.accelerator.accumulate(self.ctx.model) ë¸”ë¡ì„ ë¹ ì ¸ë‚˜ê°€ëŠ” ì‹œì ì— backward()ë¥¼ ëª¨ì•„ë‘” gradientë¥¼ í•©ì‚°í•˜ê³  optimizer.step() + optimizer.zero_grad() ê¹Œì§€ í•œ ë²ˆì— ìˆ˜í–‰.
    #             # Build gradient accumulation upon accelerator
    #             for _ in range(grad_accum_step): # ë‚´ë¶€ì—ì„œ grad_accum_stepë²ˆ mini-batch forward/backward
    #                 with self.accelerator.accumulate(self.ctx.model): #ì´ ë¸”ë¡ ì•ˆì—ì„œ ì—¬ëŸ¬ micro-batchê°€ ëª¨ì—¬ ì²˜ë¦¬ë¨.

    #                     # --- ë°ì´í„° ë°°ì¹˜ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (ë‹¤ì‹œ ì¶”ê°€) ---
    #                     try:
    #                         self.ctx.data_batch = next(data_loader_iter)
    #                     except StopIteration:
    #                         # ì´í„°ë ˆì´í„° ì¬ì„¤ì •
    #                         data_loader = self.ctx.get(f"{self.ctx.cur_split}_loader")
    #                         data_loader_iter = iter(data_loader)
    #                         setattr(self.ctx, iter_name, data_loader_iter)
    #                         self.ctx.data_batch = next(data_loader_iter)

    #                     # data_batch ì„¤ì • í›„ í›… í˜¸ì¶œ
    #                     for hook in hooks_set["on_batch_start"]:
    #                         hook(self.ctx)

    #                     for hook in hooks_set["on_batch_forward"]:
    #                         hook(self.ctx)

    #                     for hook in hooks_set["on_batch_backward"]:
    #                         hook(self.ctx)

    #                     for hook in hooks_set["on_batch_end"]:
    #                         hook(self.ctx)



    #         else: #(ë¹„-accelerator ëª¨ë“œì¼ ë•Œ) ì‹¤ì œ ë¯¸ë‹ˆë°°ì¹˜ ì¸ë±ìŠ¤ ê´€ë¦¬. fixedëœ effective batch ë‚´ì—ì„œ ì„¸ë¶„í™”í•˜ì—¬ ì‘ì—….
    #             for idx in range(grad_accum_step): #ì´ forë¬¸ì´ ë” ë“¤ì–´ê°€ëŠ”ê²Œ accelerate ë²„ì „ê³¼ì˜ ì°¨ì´. idxëŠ” fixedëœ effective batch ë‚´ì—ì„œ ëª‡ë²ˆì§¸ micro batchì¸ì§€ì— ëŒ€í•œ ì„¤ëª….
    #                 self.ctx.cur_batch_i = CtxVar(
    #                     batch_i * grad_accum_step + idx, LIFECYCLE.BATCH) #batch_i * grad_accum_step + idx ëŠ” ì „ì²´ ì—í­ ë‚´ì—ì„œ ì§€ê¸ˆ ì²˜ë¦¬ ì¤‘ì¸ ì‹¤ì œ ë¯¸ë‹ˆë°°ì¹˜ ë²ˆí˜¸ (0â€¦99). 

    #                 #ì—¬ê¸°ì„œëŠ” batch_iê°€ micro batchë¥¼ ì˜ë¯¸í•˜ëŠ” ìƒí™©. í›…(on_batch_*)ê°€ micro-batch ë‹¨ìœ„ë¡œ ë§¤ forward/backwardë§ˆë‹¤ í˜¸ì¶œë©ë‹ˆë‹¤.
    #                 for hook in hooks_set["on_batch_start"]:
    #                     hook(self.ctx)

    #                 for hook in hooks_set["on_batch_forward"]:
    #                     hook(self.ctx)

    #                 for hook in hooks_set["on_batch_backward"]:
    #                     hook(self.ctx)

    #                 for hook in hooks_set["on_batch_end"]:
    #                     hook(self.ctx)


    #             if self.ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
    #                 if (self.ctx.cur_batch_i + 1) % grad_accum_step == 0:
    #                     current_lr = self.ctx.optimizer.param_groups[0]['lr']
    #                     round_num = getattr(self.ctx, 'cur_round_i', 'N/A')
    #                     client_id = getattr(self.ctx, 'ID', 'N/A')
    #                     logger.info(
    #                       f"Client #{client_id} Round #{round_num} "
    #                       f"Local Step #{self.ctx.cur_batch_i+1}: LR = {current_lr:.2e}"
    #                     )


    #         # Break in the final epoch
    #         if self.ctx.cur_mode in [
    #                 MODE.TRAIN, MODE.FINETUNE
    #         ] and self.ctx.cur_epoch_i == self.ctx.num_train_epoch - 1:# í•™ìŠµ/íŒŒì¸íŠœë‹ ëª¨ë“œ í™•ì¸ ë° ë§ˆì§€ë§‰ ì—í­ì¸ì§€ í™•ì¸
    #             if batch_i >= self.ctx.num_train_batch_last_epoch - 1: #ë§ˆì§€ë§‰ ì—í­ì˜ ì‹¤ì œ ìŠ¤í…(ì—…ë°ì´íŠ¸) ìˆ˜ ì´ˆê³¼ ì—¬ë¶€ íŒì •
    #                 break #ì¡°ê¸° ì¢…ë£Œ(break)



 
    # def _hook_on_fit_start_numerical_precision(self, ctx):
    #     if self.cfg.train.is_enable_half:
    #         if not ctx.cfg.llm.deepspeed.use and \
    #            not ctx.cfg.llm.accelerator.use:
    #             ctx.model.to(torch.bfloat16)

    # --- [ìˆ˜ì • 5] _hook_on_fit_start_initì—ì„œ ë¡œë” ìƒì„± ë¡œì§ ì œê±° ---
    def _hook_on_fit_start_init(self, ctx):  #accelerate ë° deepspeed ì§€ì› ì¶”ê°€

        """ì„¸ ê°€ì§€ ê²½ìš°ë¡œ ë‚˜ë‰©ë‹ˆë‹¤:
        âœ… Accelerator ì‚¬ìš© ì‹œ

        self.accelerator.prepare(...) â†’ model, optimizer, dataloader, scheduler ëª¨ë‘ ê°ì‹¸ì„œ Mixed precision, DDP ë“±ì„ ì²˜ë¦¬í•´ì¤Œ
        
        âœ… Deepspeed ì‚¬ìš© ì‹œ ->ì´ê±´ í•´ë‹¹ì•ˆí•˜ë‹ˆ ì•ˆë´ë„ ë  ê²ƒ ê°™ìŒ.
        deepspeed.initialize(...)â†’ deepspeed ë°©ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ë¶„ì‚°/íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ì´ˆê¸°í™”


        âœ… ê¸°ë³¸ PyTorchë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        â†’ ê·¸ëƒ¥ .to(device) í›„ ì˜µí‹°ë§ˆì´ì € ì„¸íŒ…
        
        """

        # --- ë¡œë” ë³µì›: ì´ì „ ë¼ìš´ë“œì—ì„œ ì§€ì› ë˜ train/val/test ë¡œë”ë¥¼ ë‹¤ì‹œ ë°”ì¸ë”© ---
        # self.ctx.data ì— ë”°ë¼ ë‘ ì¼€ì´ìŠ¤ë¥¼ ëª¨ë‘ ì§€ì›:
        #   1) ì´ë¯¸ DataLoader ë¥¼ ë“¤ê³  ìˆëŠ” dict í˜•íƒœ: self.ctx.data['train'|'val'|'test']
        #   2) raw dataset ì„ ë“¤ê³  ìˆëŠ” ì»¨í…Œì´ë„ˆ: ctx.get(f"{split}_data") ë˜ëŠ” self.ctx.data.<split>_data
        for split in ["train", "val", "test"]:
            loader_key = f"{split}_loader"
            if getattr(ctx, loader_key, None) is None:
                # (1) dictì— DataLoaderê°€ ì§ì ‘ ë“¤ì–´ì˜¨ ê²½ìš°
                if isinstance(self.ctx.data, dict) and split in self.ctx.data:
                    setattr(ctx, loader_key, self.ctx.data[split])
                else:
                    # (2) raw datasetì—ì„œ ìƒˆë¡œ ë¡œë”ë¥¼ ë§Œë“ ë‹¤
                    raw = ctx.get(f"{split}_data", None)
                    if raw is None and hasattr(self.ctx.data, f"{split}_data"):
                        raw = getattr(self.ctx.data, f"{split}_data")
                    if raw is not None:
                        dl = get_dataloader(WrapDataset(raw), self.cfg, split)
                        setattr(ctx, loader_key, ReIterator(dl))
        # (ì•ˆì „) ì´ì „ ë¼ìš´ë“œ ì”ì—¬ ì´í„°ë ˆì´í„°ê°€ ë‚¨ì•„ìˆì§€ ì•Šë„ë¡ ë³´ì¥
        for it_name in ["train_loader_iter", "val_loader_iter", "test_loader_iter"]:
            if hasattr(ctx, it_name):
                delattr(ctx, it_name)



        # --- [í•µì‹¬ ì¶”ê°€ 1] ë§¤ ë¼ìš´ë“œ accelerator ìƒˆë¡œ ìƒì„± ---
        if ctx.cfg.llm.accelerator.use:
            logger.info("Re-creating Accelerator for the new round.")
            self.accelerator = Accelerator(
                gradient_accumulation_steps=self.grad_accum_step,
                mixed_precision='bf16'
            )
            ctx.device = self.accelerator.device

            # ì›ë³¸ ëª¨ë¸ ì¶”ì¶œ
            unwrapped_model = ctx.model
            while hasattr(unwrapped_model, 'module'):
                unwrapped_model = unwrapped_model.module
            if hasattr(unwrapped_model, 'sharding'):
                unwrapped_model.sharding()

            # (í•™ìŠµ ì‹œ) ì˜µí‹°ë§ˆì´ì €/ìŠ¤ì¼€ì¤„ëŸ¬ ì¤€ë¹„
            if ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
                cfg_optimizer = ctx.cfg[ctx.cur_mode].optimizer
                if cfg_optimizer.type == 'AdamW':
                    adamw_kwargs = {'lr': cfg_optimizer.lr, 'betas': cfg_optimizer.betas}
                    ctx.optimizer = AdamW(unwrapped_model.parameters(), **adamw_kwargs)
                else:
                    ctx.optimizer = get_optimizer(unwrapped_model, **cfg_optimizer)

                ctx.scheduler = get_scheduler(ctx.optimizer, **ctx.cfg[ctx.cur_mode].scheduler)

                current_lr = ctx.optimizer.param_groups[0]['lr']
                
                round_num = getattr(ctx, 'current_round_num', 'N/A')
                logger.info(f"Round #{round_num} - Initializing with LR: {current_lr}")

                # â›”ï¸ ì—¬ê¸°ì„œ DataLoaderë¥¼ prepareì— ë„˜ê¸°ì§€ ì•ŠìŠµë‹ˆë‹¤!
                ctx.model, ctx.optimizer = self.accelerator.prepare(unwrapped_model, ctx.optimizer)
            else:
                # í‰ê°€ ëª¨ë“œ: ëª¨ë¸ë§Œ prepare
                ctx.model = self.accelerator.prepare(unwrapped_model)


        elif ctx.cfg.llm.deepspeed.use: #FALSE
            # Enable deepspeed
            # TODO: save ctx.optimizer and ctx.scheduler
            # TODO: should clients share the same `ctx.model_engine`?
            assert deepspeed is not None, "Please install deepspeed."
            if not hasattr(ctx, 'model_engine'):
                ctx.model_engine, ctx.optimizer, _, ctx.scheduler = \
                    deepspeed.initialize(
                        config=ctx.cfg.llm.deepspeed.ds_config,
                        model=ctx.model,
                        model_parameters=filter(lambda p: p.requires_grad,
                                                ctx.model.parameters()),
                    )
            # Enable all cards from 0
            ctx.device = ctx.model_engine.local_rank
            # if ctx.cfg.train.is_enable_half:
            #     ctx.fp16 = ctx.model_engine.fp16_enabled()

        else:
            # prepare model and optimizer
            ctx.model.to(ctx.device)
            if ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
                ctx.optimizer = get_optimizer(ctx.model, **ctx.cfg[ctx.cur_mode].optimizer)
                
                if not hasattr(self, 'scheduler') or self.scheduler is None:
                    self.scheduler = get_scheduler(ctx.optimizer, **ctx.cfg[ctx.cur_mode].scheduler)
                ctx.scheduler = self.scheduler

                # [ë””ë²„ê¹… ë¡œê·¸] í˜„ì¬ LR ì¶œë ¥
                current_lr = ctx.optimizer.param_groups[0]['lr']
                round_num = getattr(ctx, 'cur_round_i', 'N/A')
                logger.info(f"Round #{round_num} - Current Learning Rate: {current_lr}")

        # prepare statistics
        ctx.loss_batch_total = CtxVar(0., LIFECYCLE.ROUTINE)
        ctx.loss_regular_total = CtxVar(0., LIFECYCLE.ROUTINE)
        ctx.num_samples = CtxVar(0, LIFECYCLE.ROUTINE)
        ctx.ys_true = CtxVar([], LIFECYCLE.ROUTINE)
        ctx.ys_prob = CtxVar([], LIFECYCLE.ROUTINE)

        if hasattr(ctx, 'ys_pred'): 
            ctx.ys_pred = CtxVar([], LIFECYCLE.ROUTINE)

        if ctx.cur_mode in [MODE.TRAIN, MODE.FINETUNE]:
            ctx.model.train()
        else:  # MODE.TEST or MODE.VAL
            ctx.model.eval()

            
    def _hook_on_epoch_start(self, ctx):
        pass

 

    def _hook_on_batch_forward(self, ctx): #ctx.data_batch â†’ input_ids, attention_mask, labelsë¡œ ëª…ì‹œ ì²˜ë¦¬ + ëª¨ë¸ í˜¸ì¶œ ë°©ì‹ ë³€ê²½. ê¸°ì¡´ toprch trainerëŠ” CNN, MLP, BERT ìš©ì´ë¼ LLMìš©ì€ ì•„ë‹ˆë¼ì„œ OVERRIDE í•´ì•¼í•¨.

        """ 
        (ê¸°ì¡´)->ì¼ë°˜ ëª¨ë¸ (ì˜ˆ: CNN, MLP, BERT ë“±)ìš©
        x, label = [_.to(ctx.device) for _ in ctx.data_batch]
        pred = ctx.model(x)
        loss = ctx.criterion(pred, label)

        ğŸ” íŠ¹ì§•
        ctx.data_batchëŠ” (x, label) íŠœí”Œ í˜•íƒœ

        model(x)ë§Œìœ¼ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥

        loss = criterion(pred, label)ë¡œ ì†ì‹¤ ê³„ì‚°

        ë§¤ìš° ë‹¨ìˆœí•˜ê³  ì§ê´€ì ì¸ êµ¬ì¡°



        (OVERRIDE ë²„ì „)->LLM í•™ìŠµìš© override


        input_ids = ctx.data_batch['input_ids']
        labels = ctx.data_batch['labels']
        attention_mask = ctx.data_batch['attention_mask']
        ...
        outputs = model(input_ids=..., labels=..., attention_mask=...)


        ğŸ” ì£¼ìš” ë³€ê²½ ì´ìœ  ìš”ì•½
        ë³€ê²½ ìš”ì†Œ	ì´ìœ 
        data_batchê°€ dictë¡œ ë°”ë€œ	LLMì€ (input_ids, attention_mask, labels) í˜•íƒœë¡œ í•™ìŠµ
        model(input_ids=..., labels=...) ì‚¬ìš©	Huggingface LLMì€ forward()ì—ì„œ lossê¹Œì§€ ê°™ì´ ë°˜í™˜í•¨
        ctx.model_engine(...) ë¶„ê¸°	DeepSpeed ë“± ì‚¬ìš©í•  ê²½ìš° Acceleratorë‚˜ Engineì´ ëª¨ë¸ì„ wrapping
        skip_this_batch ì¶”ê°€	LLM í•™ìŠµì—ì„œ NaN lossê°€ ë¹ˆë²ˆ â†’ ë°©ì–´ ë¡œì§ í•„ìš”


        """


        if ctx.cfg.llm.accelerator.use: #ì°¸ê³ 


            #LLM í•™ìŠµìš© Datasetì€ ë³´í†µ tokenized_dictë¥¼ ë°˜í™˜->{'input_ids': Tensor, 'labels': Tensor, 'attention_mask': Tensor}
            #acceleratorëŠ” ì…ë ¥ í…ì„œë¥¼ ìë™ìœ¼ë¡œ ë””ë°”ì´ìŠ¤ì— ì˜¬ë ¤ì¤˜ì„œ .to(ctx.device)ê°€ í•„ìš” ì—†ìŒ.


            #input_ids: [101,  42,  53,  78,   2]
            #labels:    [101,  42,  53,  78,   2]  # í˜¹ì€ ì¼ë¶€ -100 í¬í•¨
            #ì´ë ‡ê²Œ ê±°ì˜ ê°™ì§€ë§Œ, loss ê³„ì‚°ì—ì„œ ë¬´ì‹œí•  í† í°ì€ labelsì—ì„œë§Œ ë°”ë€œ.
            
            input_ids = ctx.data_batch['input_ids'].to(ctx.device)
            labels = ctx.data_batch['labels'].to(ctx.device)
            attention_mask = ctx.data_batch['attention_mask'].to(ctx.device)

            #ëª¨ë¸ í˜¸ì¶œì´ model(x) â†’ model(input_ids=..., labels=...)ë¡œ ë°”ë€œâ†’ lossë¥¼ ì§ì ‘ criterionìœ¼ë¡œ ê³„ì‚°í•˜ì§€ ì•Šê³ , ëª¨ë¸ ìì²´ê°€ ê³„ì‚°í•´ì„œ outputs.lossë¡œ ì¤Œ. lossëŠ” cross-entropyë¡œ ì ìš©í•˜ê²Œ hugging faceê°€ ì„¤ê³„. forwardë¥¼ overrideí•˜ë©´ loss ë°”ê¾¸ëŠ” ê²ƒ ê°€ëŠ¥.
            outputs = ctx.model(input_ids=input_ids,
                                labels=labels,
                                attention_mask=attention_mask) # ìë™ìœ¼ë¡œ ëª¨ë¸ê³¼ ë°°ì¹˜ í…ì„œ ëª¨ë‘ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™

        elif ctx.cfg.llm.deepspeed.use: #ctx.model_engine ê¸°ë°˜ìœ¼ë¡œ outputs ë½‘ì•„ë‚¸ë‹¤.

            input_ids = ctx.data_batch['input_ids'].to(ctx.device)
            labels = ctx.data_batch['labels'].to(ctx.device)
            attention_mask = ctx.data_batch['attention_mask'].to(ctx.device)


            outputs = ctx.model_engine(input_ids=input_ids,
                                       labels=labels,
                                       attention_mask=attention_mask)

        else:#ì°¸ê³ , #ctx.model ê¸°ë°˜ìœ¼ë¡œ outputs ë½‘ì•„ë‚¸ë‹¤.
            input_ids = ctx.data_batch['input_ids'].to(ctx.device)
            labels = ctx.data_batch['labels'].to(ctx.device)
            attention_mask = ctx.data_batch['attention_mask'].to(ctx.device)



            outputs = ctx.model(input_ids=input_ids,
                                labels=labels,
                                attention_mask=attention_mask)

        logits = outputs.logits #ì¼ë°˜ì ìœ¼ë¡œ LLMì—ì„œëŠ” [batch_size, seq_len, vocab_size] shapeì˜ tensor
        loss = outputs.loss #ì¼ë¶€ ëª¨ë¸ì—ì„œ reduction='none'ì´ë©´ shapeê°€ [batch_size] í˜¹ì€ [batch_size, seq_len]ì¼ ìˆ˜ë„ ìˆì§€ë§Œ, ëŒ€ë¶€ë¶„ì€ 1ê°œì˜ ìŠ¤ì¹¼ë¼ ê°’

        #NaN lossê°€ ë°œìƒì‹œí‚¤ëŠ” batch ê±´ë„ˆë›°ê¸° ìœ„í•œ ë°©ì–´ ë¡œì§
        if torch.isnan(loss): #LM í•™ìŠµì—ì„œëŠ” ì¢…ì¢… NaN lossê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ-> labelì´ ëª¨ë‘ -100 (ignore index). precision ë¬¸ì œ (e.g., bf16/float16). exploding gradients, bad initialization
            ctx.skip_this_batch = CtxVar(True, LIFECYCLE.BATCH) #ë‹¤ë¥¸ hookì—ì„œ ì´ ê°’ì´ Trueë©´ ì´ ë°°ì¹˜ë¥¼ ê±´ë„ˆëœ€. (ì˜ˆ: loss.backward() ìŠ¤í‚µ)
            logger.warning('Skip the batch due to the loss is NaN, '
                           'it may be caused by exceeding the precision or '
                           'invalid labels.')
        else:
            ctx.skip_this_batch = CtxVar(False, LIFECYCLE.BATCH)

        ctx.y_true = CtxVar(labels, LIFECYCLE.BATCH) #shape: [batch_size, seq_len]
        ctx.y_prob = CtxVar(logits, LIFECYCLE.BATCH) # shape: [batch_size, seq_len, vocab_size]
 
        ctx.loss_batch = CtxVar(loss, LIFECYCLE.BATCH)
        ctx.batch_size = CtxVar(len(labels), LIFECYCLE.BATCH)

    def _hook_on_batch_backward(self, ctx): #accelerate, deepspeedì— ë”°ë¥¸ backward, step, zero_grad ì²˜ë¦¬ ë¶„ê¸°

        """
        Accelerator ë˜ëŠ” Deepspeed ì‚¬ìš© ì‹œ ì „ìš© backward/step ë¡œì§
            self.accelerator.backward()

            ctx.model_engine.backward() ë“±

        ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°, ì¼ë°˜ loss.backward()ì— grad_accum_step ê³ ë ¤í•˜ì—¬ ë‚˜ëˆ ì¤Œ

        """


        if ctx.skip_this_batch: #ìŠ¤í‚µ í”Œë˜ê·¸(skip_this_batch)ê°€ ì¼œì ¸ ìˆìœ¼ë©´ ì•„ë¬´ ì‘ì—…ë„ í•˜ì§€ ì•Šê³  ë°”ë¡œ ë¦¬í„´
            return

        if ctx.cfg.llm.accelerator.use:
            # Accelerateê°€ grad accumulationì„ ê´€ë¦¬í•˜ë¯€ë¡œ ì†ì‹¤ì„ ë‚˜ëˆ„ì§€ ì•ŠìŠµë‹ˆë‹¤.
            self.accelerator.backward(ctx.loss_task)
            # âœ… ëˆ„ì  ê²½ê³„(sync_gradients=True)ì—ì„œë§Œ step/zero_grad ì‹¤í–‰
            if getattr(self.accelerator, "sync_gradients", True):
                # (ë³´ì™„) ê²½ê³„ì—ì„œë§Œ gradient clipping ìˆ˜í–‰
                if getattr(ctx, "grad_clip", 0) and ctx.grad_clip > 0:
                    try:
                        self.accelerator.clip_grad_norm_(ctx.model.parameters(), ctx.grad_clip)
                    except Exception:
                        torch.nn.utils.clip_grad_norm_(ctx.model.parameters(), ctx.grad_clip)
                ctx.optimizer.step()
                if ctx.scheduler is not None:
                    ctx.scheduler.step()
                ctx.optimizer.zero_grad()

        elif ctx.cfg.llm.deepspeed.use: #FALSE
            ctx.model_engine.backward(ctx.loss_task)
            ctx.model_engine.step()
            if ctx.scheduler is not None:
                ctx.scheduler.step()

        else:
            (ctx.loss_task / self.grad_accum_step).backward()

            if (ctx.cur_batch_i + 1) % self.grad_accum_step == 0: #ì¡°ê±´ë¶€ ì—…ë°ì´íŠ¸. cur_batch_i+1) % grad_accum_step == 0ì¼ ë•Œë§Œ
                if ctx.grad_clip > 0: #ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘. ->ctx.grad_clip > 0ì¼ ê²½ìš° clip_grad_norm_ ì ìš©
                    torch.nn.utils.clip_grad_norm_(ctx.model.parameters(),
                                                   ctx.grad_clip)
                ctx.optimizer.step()
                if ctx.scheduler is not None:
                    ctx.scheduler.step()
                ctx.optimizer.zero_grad()

        # # move the training data to cpu.
        # ctx.data_batch['input_ids'].cpu()
        # ctx.data_batch['labels'].cpu()
        # ctx.data_batch['attention_mask'].cpu()

        # move the training data to cpu (ì•ˆì „í•˜ê²Œ í‚¤ í™•ì¸)
        if 'input_ids' in ctx.data_batch:
            ctx.data_batch['input_ids'].cpu()
        if 'labels' in ctx.data_batch:
            ctx.data_batch['labels'].cpu()
        if 'attention_mask' in ctx.data_batch:
            ctx.data_batch['attention_mask'].cpu()


    def _hook_on_batch_end(self, ctx): #NaN lossì¼ ê²½ìš° retry ë¡œì§ ì¶”ê°€

        """
        ê¸°ë³¸ ë¡œì§ + loss == NaNì¼ ê²½ìš° batchë¥¼ retry

        if ctx.skip_this_batch:
            if ctx.cfg.llm.retry_on_nan_loss:
                self._run_batch(...)
        """
        if ctx.skip_this_batch:
            if ctx.cfg.llm.retry_on_nan_loss:
                # Retry with new data in train and finetune
                if ctx.cur_mode == MODE.TRAIN:
                    self._run_batch(self.hooks_in_train, run_step=1)
                elif ctx.cur_mode == MODE.FINETUNE:
                    self._run_batch(self.hooks_in_ft, run_step=1)
            return

        ctx.num_samples += ctx.batch_size
        ctx.loss_batch_total += ctx.loss_batch.item() * ctx.batch_size
        ctx.loss_regular_total += float(ctx.get("loss_regular", 0.))


    def _hook_on_fit_end(self, ctx): #ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼, í‰ê·  lossë§Œ ê³„ì‚°. overrideë˜ëŠ” ê³¼ì •ì—ì„œ accuracyëŠ” ë¹ ì§„ë‹¤.

        return

    def _hook_on_fit_end_free_space(self, ctx):
        # ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬, ì„ì‹œ í…ì„œ, ì´í„°ë ˆì´í„°ë§Œ ì •ë¦¬
        attributes_to_delete = [
            'optimizer', 'scheduler', 'loss_batch', 'loss_task', 'loss_regular',
            'loss_batch_total', 'loss_regular_total', 'y_true', 'y_prob',
            'ys_true', 'ys_pred',
            'data_batch', 'grad', 'model_engine', 'skip_this_batch',
            # ë°ì´í„°ë¡œë”ì™€ ì´í„°ë ˆì´í„°ë¥¼ ëª¨ë‘ ì‚­ì œí•˜ì—¬ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ë°©ì§€
            'train_loader', 'val_loader', 'test_loader',
            'train_loader_iter', 'val_loader_iter', 'test_loader_iter'
        ]

        # ë¡œê·¸ ì¶”ê°€ (ì„ íƒì‚¬í•­ì´ì§€ë§Œ ë””ë²„ê¹…ì— ìœ ìš©)
        if hasattr(ctx, 'rank') and ctx.rank == 0:
            deleted_attrs = [attr for attr in attributes_to_delete if hasattr(ctx, attr)]
            logger.info(f"[Memory Cleanup] Deleting attributes: {deleted_attrs}")


        for attr in attributes_to_delete:
            if hasattr(ctx, attr):
                # delattrì„ ì‚¬ìš©í•˜ì—¬ ctx ê°ì²´ì—ì„œ í•´ë‹¹ ì†ì„± ì°¸ì¡°ë¥¼ ì™„ì „íˆ ì œê±°
                delattr(ctx, attr)

        # --- [í•µì‹¬] accelerator ê°ì²´ ìì²´ë¥¼ ì‚­ì œ ---
        if hasattr(self, 'accelerator'):
            del self.accelerator
            logger.info("Accelerator object has been deleted.")

        gc.collect()
        torch.cuda.empty_cache()



    def _hook_on_batch_forward_flop_count(self, ctx): #PASSí•´ë„ ë ë“¯

        """
        ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ LLMì˜ input (input_ids, attention_mask)ì„ ì´ìš©í•´ FLOPsë¥¼ ê³„ì‚°.

        fvcore.nn.FlopCountAnalysisë¥¼ ì‚¬ìš©í•¨.
        """



        """
        The monitoring hook to calculate the flops during the fl course

        Note:
          For customized cases that the forward process is not only \
          based on ctx.model, please override this function (inheritance \
          case) or replace this hook (plug-in case)

          The modified attributes and according operations are shown below:
            ==================================  ===========================
            Attribute                           Operation
            ==================================  ===========================
            ``ctx.monitor``                     Track average flops
            ==================================  ===========================
        """

        # The process may occupy a large amount of video memory
        # if the garbage collection is not triggered in time
        # when there is plenty of video memory left. Set
        # `eval.count_flops = False` to avoid this.
        if not isinstance(ctx.monitor, Monitor):
            logger.warning(
                f"The trainer {type(self)} does contain a valid monitor, "
                f"this may be caused by initializing trainer subclasses "
                f"without passing a valid monitor instance."
                f"Please check whether this is you want.")
            return

        if self.cfg.eval.count_flops and ctx.monitor.flops_per_sample == 0:
            # calculate the flops_per_sample
            try:
                input_ids = ctx.data_batch['input_ids'].to(ctx.device)
                labels = ctx.data_batch['labels'].to(ctx.device)
                attention_mask = ctx.data_batch['attention_mask'].to(
                    ctx.device)
                from fvcore.nn import FlopCountAnalysis
                if isinstance(ctx.model, AdapterModel):
                    flops_one_batch = FlopCountAnalysis(
                        ctx.model.model,
                        inputs=(input_ids, attention_mask)).total()
                else:
                    flops_one_batch = FlopCountAnalysis(
                        ctx.model, inputs=(input_ids, attention_mask)).total()
                ctx.monitor.track_avg_flops(flops_one_batch, ctx.batch_size)
            except Exception as e:
                logger.warning("When using count flops functions, torch's "
                               "garbage collection mechanism may not be "
                               "timely resulting in OOM, please set "
                               "`cfg.eval.count_flops` to `False` "
                               "to avoid error or warning like this.")
                logger.error(e)
                # Raise warning at the first failure
                logger.warning(
                    "current flop count implementation is for general LLM "
                    "trainer case: "
                    "1) ctx.data_batch contains [input_ids, labels, "
                    "attn_mask]; and 2) the ctx.model takes first two "
                    "arguments should be and attention_mask. "
                    "If ctx.model is an adapter model, the model in 2) has "
                    "been replaced by ctx.model.model. "
                    "Please check the forward format or implement your own "
                    "flop_count function")
                ctx.monitor.flops_per_sample = -1

        # by default, we assume the data has the same input shape,
        # thus simply multiply the flops to avoid redundant forward
        ctx.monitor.total_flops += ctx.monitor.flops_per_sample * \
            ctx.batch_size


def call_llm_trainer(trainer_type):
    if trainer_type == 'llmtrainer':
        trainer_builder = LLMTrainer
        return trainer_builder


register_trainer('llmtrainer', call_llm_trainer)
